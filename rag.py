# import numpy as np
# from openai import OpenAI
# from sklearn.metrics.pairwise import cosine_similarity

# # 1. –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –∫–ª–∏–µ–Ω—Ç–∞
# client = OpenAI(
#     base_url='http://localhost:11434/v1',
#     api_key='ollama',
# )

# # --- –≠–¢–ê–ü 1: –ù–ê–®–ê –ë–ê–ó–ê –ó–ù–ê–ù–ò–ô (–°–µ–∫—Ä–µ—Ç–Ω—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã) ---
# # –í —Ä–µ–∞–ª—å–Ω–æ—Å—Ç–∏ —Ç—É—Ç –±—ã–ª–æ –±—ã —á—Ç–µ–Ω–∏–µ PDF –∏–ª–∏ Word —Ñ–∞–π–ª–æ–≤.
# documents = [
#     "–°–µ–∫—Ä–µ—Ç–Ω—ã–π –æ–±—ä–µ–∫—Ç '–û–º–µ–≥–∞' –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –ø–æ–¥ –≥–æ—Ä–æ–π –≠–ª—å–±—Ä—É—Å.",
#     "–ö–æ–¥ –¥–æ—Å—Ç—É–ø–∞ –∫ –ª–∞–±–æ—Ä–∞—Ç–æ—Ä–∏–∏: 77-Alpha-99.",
#     "–ì–ª–∞–≤–Ω—ã–π —É—á–µ–Ω—ã–π –ª—é–±–∏—Ç –ø–∏—Ç—å –∑–µ–ª–µ–Ω—ã–π —á–∞–π —Å –∂–∞—Å–º–∏–Ω–æ–º.",
#     "–í —Å–ª—É—á–∞–µ —Ç—Ä–µ–≤–æ–≥–∏ –Ω—É–∂–Ω–æ –Ω–∞–∂–∞—Ç—å –∫—Ä–∞—Å–Ω—É—é –∫–Ω–æ–ø–∫—É –ø–æ–¥ —Å—Ç–æ–ª–æ–º.",
#     "–ó–∞—Ä–ø–ª–∞—Ç–∞ –æ—Ö—Ä–∞–Ω–Ω–∏–∫–∞ —Å–æ—Å—Ç–∞–≤–ª—è–µ—Ç 5000 –∑–æ–ª–æ—Ç—ã—Ö –º–æ–Ω–µ—Ç."
# ]

# print("üìö –°–æ–∑–¥–∞—é —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –¥–ª—è –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π (–ø—Ä–µ–≤—Ä–∞—â–∞—é —Ç–µ–∫—Å—Ç –≤ —Ü–∏—Ñ—Ä—ã)...")

# # –§—É–Ω–∫—Ü–∏—è –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –≤–µ–∫—Ç–æ—Ä–∞ (—ç–º–±–µ–¥–¥–∏–Ω–≥–∞) —Ç–µ–∫—Å—Ç–∞
# def get_embedding(text):
#     response = client.embeddings.create(
#         model="all-minilm", # –ò—Å–ø–æ–ª—å–∑—É–µ–º "–ë–∏–±–ª–∏–æ—Ç–µ–∫–∞—Ä—è"
#         input=text
#     )
#     return response.data[0].embedding

# # –ü—Ä–µ–≤—Ä–∞—â–∞–µ–º –≤—Å–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã –≤ –≤–µ–∫—Ç–æ—Ä—ã –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ–º –≤ —Å–ø–∏—Å–æ–∫
# doc_vectors = [get_embedding(doc) for doc in documents]

# print("‚úÖ –ë–∞–∑–∞ –∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–∞! –ì–æ—Ç–æ–≤ –æ—Ç–≤–µ—á–∞—Ç—å –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã.")
# print("-------------------------------------------------")

# # --- –≠–¢–ê–ü 2: –¶–ò–ö–õ –û–ë–©–ï–ù–ò–Ø ---
# while True:
#     user_query = input("\n–í–∞—à –≤–æ–ø—Ä–æ—Å (–∏–ª–∏ '–≤—ã—Ö–æ–¥'): ")
#     if user_query.lower() in ["–≤—ã—Ö–æ–¥", "exit"]:
#         break

#     # 1. –ü–æ–∏—Å–∫ (Retrieval)
#     # –ü—Ä–µ–≤—Ä–∞—â–∞–µ–º –≤–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è —Ç–æ–∂–µ –≤ –≤–µ–∫—Ç–æ—Ä
#     query_vector = get_embedding(user_query)

#     # –°—á–∏—Ç–∞–µ–º —Å—Ö–æ–¥—Å—Ç–≤–æ –≤–æ–ø—Ä–æ—Å–∞ —Å–æ –≤—Å–µ–º–∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞–º–∏
#     # (–°—Ä–∞–≤–Ω–∏–≤–∞–µ–º –≤–µ–∫—Ç–æ—Ä –≤–æ–ø—Ä–æ—Å–∞ —Å –∫–∞–∂–¥—ã–º –≤–µ–∫—Ç–æ—Ä–æ–º –∏–∑ –±–∞–∑—ã)
#     similarities = cosine_similarity([query_vector], doc_vectors)[0]

#     # –ù–∞—Ö–æ–¥–∏–º –∏–Ω–¥–µ–∫—Å —Å–∞–º–æ–≥–æ –ø–æ—Ö–æ–∂–µ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞ (—É –∫–æ–≥–æ —Ü–∏—Ñ—Ä–∞ –±–æ–ª—å—à–µ)
#     best_doc_index = np.argmax(similarities)
#     best_doc = documents[best_doc_index]
#     score = similarities[best_doc_index] # –ù–∞—Å–∫–æ–ª—å–∫–æ –ø–æ—Ö–æ–∂–µ (–æ—Ç 0 –¥–æ 1)

#     print(f"   (–ù–∞—à–µ–ª –≤ –±–∞–∑–µ: '{best_doc}' | –°—Ö–æ–¥—Å—Ç–≤–æ: {score:.2f})")

#     # 2. –ì–µ–Ω–µ—Ä–∞—Ü–∏—è (Generation)
#     # –ï—Å–ª–∏ —Å—Ö–æ–¥—Å—Ç–≤–æ —Å–ª–∏—à–∫–æ–º –º–∞–ª–µ–Ω—å–∫–æ–µ, –∑–Ω–∞—á–∏—Ç –∏–Ω—Ñ—ã –Ω–µ—Ç
#     if score < 0.3:
#         print("ü§ñ –ë–æ—Ç: –Ø –Ω–µ –Ω–∞—à–µ–ª –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ–± —ç—Ç–æ–º –≤ —Å–µ–∫—Ä–µ—Ç–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ö.")
#         continue

#     # –§–æ—Ä–º–∏—Ä—É–µ–º –ø—Ä–æ–º–ø—Ç (—à–ø–∞—Ä–≥–∞–ª–∫—É) –¥–ª—è Mistral
#     prompt = f"""
#     –¢—ã —Å–æ—Ç—Ä—É–¥–Ω–∏–∫ —Å–ª—É–∂–±—ã –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏. –ò—Å–ø–æ–ª—å–∑—É–π –¢–û–õ–¨–ö–û —Å–ª–µ–¥—É—é—â—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –¥–ª—è –æ—Ç–≤–µ—Ç–∞ –Ω–∞ –≤–æ–ø—Ä–æ—Å.
#     –ï—Å–ª–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –Ω–µ—Ç, —Å–∫–∞–∂–∏ "–ù–µ –∑–Ω–∞—é".
    
#     –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è: {best_doc}
    
#     –í–æ–ø—Ä–æ—Å: {user_query}
#     """

#     # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –≤ Mistral
#     response = client.chat.completions.create(
#         model="mistral",
#         messages=[{"role": "user", "content": prompt}]
#     )

#     print(f"ü§ñ –ë–æ—Ç: {response.choices[0].message.content}")
